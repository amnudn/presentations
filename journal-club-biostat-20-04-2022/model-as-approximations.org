* The paper
** The paper
\hfill

[[./quotes/abstract.png]]

** Discussion paper
- Memorial Issue for Lawrence D. Brown
- Paper in two parts: Special case of linear regression (part I, \cite{buja2019models}) and general
  case (part II, \cite{buja2019models2})
\hfill

*** Comments by
- \citeauthor*{ghanem2019discussion} (UC Davis and Washington University in St. Louis)
- \citeauthor*{rinaldo2019comment} (Carnegie Mellon University, Pittsburgh)
- \citeauthor*{whitney2019comment} (Imperial College London, University of Washington, Seattle)
- and others.

** Overall idea
Understand what is estimated with linear a linear regression (or more general M-estimators) when the
model is mis-specified. 

\hfill

Define the parameter $\beta$ as a functional defined on the data distribution $P \in \mathcal{P}$:

\hfill

[[./quotes/sect3-main-def.png]]

** One consequence
[[./quotes/sect4-implication.png]]

[[./quotes/sect4-fig2.png]]

** Is this a problem?
This seems to only be a problem because we do not understand how to interpret $\beta(P)$.

*** Average treatment effect (ATE)
The ATE, \[\E[Y^1 - Y^0] = \E_P{[ \E_P[Y \mid X, A=1] - \E_P[Y \mid X, A=0]]}, \] should naturally
depend on the background distribution of $X$.

*** Conditional average treatment effect (CATE)
The CATE, \[ \E[Y^1 - Y^0 \mid X=x] = \E_P[Y \mid X=x, A=1] - \E_P[Y \mid X=x, A=0], \] would not
depend on the background distribution $X$ (right?).

** Interpretation of "slopes" in the presence of non-linearity
*** overlay block 
:PROPERTIES:
:BEAMER_act: <1>
:BEAMER_env: onlyenv
:END:

[[./quotes/sect10-interpretation.png]]

*** overlay block 
:PROPERTIES:
:BEAMER_act: <2>
:BEAMER_env: onlyenv
:END:

[[./quotes/sect10-figure.png]]

[[./quotes/sect10-interpretation-text.png]]

* Discussion papers
** The best approximation depends on how you measure
***                                                                 :B_quote:
:PROPERTIES:
:BEAMER_env: quote
:END:
In the context of prediction, the objective is often to minimize a particular criterion or scoring
rule. ... [In the] case of misspecification, it is not clear which criterion should be used for
estimation. In the context of forecasting conditional probabilities of binary outcomes, Elliott,
Ghanem and Krüger (2016) examine this question and illustrate that *the choice of scoring rule
yields different best approximations to the true conditional probability function of the outcome of
interest under misspecification*, except under restrictive conditions. \citep{ghanem2019discussion}

** Predictive performance
\cite{rinaldo2019comment} argue that we should give up the parameter $\beta$ and instead consider:

*** Proper causal effect
$\beta$ is often mis-interpreted as a causal quantity effect. Drop the parameter $\beta$ and instead
define a causal quantity of interest rigorously using counterfactuals, SEMs, DAGs.

*** Variable importance measure
Non-parametric variable importance measures defined without reference to a model, for instance
proportion of variance explained or Shapley values.

** The best approximation is ill-defined when data is coarsened

#+attr_latex: :width 7cm
[[./quotes/comment-whitney-figure.png]]

***                                                                 :B_quote:
:PROPERTIES:
:BEAMER_env: quote
:END:
*The fact that the censoring distribution defines the estimand is particularly alarming*. In
commenting on this finding, O’Quigley (2008) states that the partial likelihood-based regression
functional is not itself particularly useful nor interpretable -- we agree with this viewpoint.
\citep{whitney2019comment}

* Additional thoughts
** Fully non-parametric (model-free) parameter definition

*** Model $\rightarrow$ parameter (more or less interpretable)
Extend parameter from linear (or other) model to general (non-parametric) setting. The parameter
interpretation simplifies to well-known quantity when the model is correct
\citep{buja2019models,buja2019models2}.

*** Interpretable parameter $\rightarrow$ estimation by using model
Define parameter of interest directly on the non-parametric family of probability measure --
model-agnostic parameter \citep{whitney2019comment}. Separate parameter definition and estimation
completely.

** Flawed models as a fact of life?
Back to the main paper: In the end we are going to use a model.
[[./quotes/sect10-model-approx.png]]

The effect of estimation the nuisance parameter with an approximate nuisance model on the estimator
of a /target parameter/:
- Assume the parameter of interest $\Psi$ is identified through the nuisance parameter $\nu$, i.e.,
  $\Psi(P) = \tilde\Psi(\nu(P))$.
- If $\hat \nu$ is an estimator of $\nu$, then what effect does mis-specification/approximation for
  the nuisance component have on the plug-in estimator $\hat \Psi = \tilde\Psi(\hat \nu)$?

** \normalsize Illustration of the effect of approximate nuisance model on target estimator
*** Some R code                                                    :noexport:

Try to include some interaction terms.

Also try to get back a closer fit to the right.

Try to see what happens with fewer observations?

#+BEGIN_SRC R :results output verbatim  :exports results  :session *R* :cache yes
  library(glmnet)
  library(data.table)
  library(ggplot2)

  effect.size <- .2
  sim.dat <- function(n=1000, p=10){
    X0 = matrix(rnorm(n*p), nrow=n)
    X.term = .1*X0[, 1] + .2*X0[, 2]^2 + .2*X0[, 3]^3
    Y1 = X.term + effect.size + rnorm(n)
    Y0 = X.term + rnorm(n)
    A = 1*(runif(n) < X0[, 3])
    Y = rep(as.numeric(NA), n)
    Y[A == 1] = Y1[A == 1]
    Y[A == 0] = Y0[A == 0]
    return(data.table(Y, A, X0, Y0, Y1))
  }

  sim.est <- function(M, lambda=exp(seq(5, -10, length.out=200)), p = 10, alpha=0, ...){
    out <- do.call(rbind, lapply(1:M, function(m){
      train.dat <- sim.dat(p = p)
      ## True model
      true.m <- lm(Y ~ V1 + I(V2^2) + I(V3^3) + A, data = train.dat)
      ## ML model:
      model <- glmnet(train.dat[, -1], train.dat[,Y], alpha=alpha, lambda=lambda, ...)
      ## Nuisance fit
      test <- sim.dat(n=10000, p = p)
      pred.test <- predict(model, newx=as.matrix(test[, -1]))   
      est.nui <- data.table(lambda=lambda,fit=apply((pred.test - test[, Y])^2, 2, mean),model="ridge",parameter = "nuisance.msefit")
      ## Target fit
      copy.dat1 <- copy(train.dat)[, A := 1]
      copy.dat0 <- copy(train.dat)[, A := 0]
      target.true = data.table(lambda = lambda,fit = mean(predict(true.m, newdata = copy.dat1)) - mean(predict(true.m, newdata = copy.dat0)),model = "true", parameter = "target")
      target.ml = data.table(lambda=lambda,fit = apply(predict(model, newx=as.matrix(copy.dat1[, -1]))-predict(model, newx=as.matrix(copy.dat0[, -1])), 2, mean),model="ridge",parameter = "target")
      return(rbind(target.true, target.ml, est.nui)[, sim := m])    
    }))
    ## out[, bias := fit - effect.size]
    return(out[])
  }

  set.seed(23)
  tt0 <- sim.est(M = 200, exp(seq(3, -10, length.out=100)), p = 30)
#+END_SRC

#+RESULTS[(2022-04-19 23:05:30) d4debb300ed6bd5ad4c1b992c755f69b6c49aec0]:
: Loading required package: Matrix
: Loaded glmnet 4.1-3
: data.table 1.14.2 using 4 threads (see ?getDTthreads).  Latest news: r-datatable.com

*** Illustration                                                 :B_noheader:
:PROPERTIES:
:BEAMER_env: noheader
:END:
#+BEGIN_SRC R :results graphics file :session *R* :cache yes :exports results :file ./fig-approximate-nuisance.pdf :width 9 :height 5
  ggplot(tt0[parameter == "target", .(mean.fit=mean(fit), lwr.fit = quantile(fit, probs = 0.025), upr.fit = quantile(fit, probs = 0.975)), .(model, lambda)], aes(x=log(lambda), y=mean.fit) ) + theme_classic() +
    geom_ribbon(aes(fill = model, ymin = lwr.fit,ymax = upr.fit), alpha = 0.15) +
    geom_hline(yintercept = effect.size, col = "gray", lty = 2, size=1.2) + 
    geom_line(size=1.2, aes(col = model)) +
    geom_vline(xintercept = tt0[parameter == "nuisance.msefit", .(mean.mse=mean(fit)), lambda][which.min(mean.mse), log(lambda)], col = "gray", size=1.2)
#+END_SRC

#+RESULTS[(2022-04-19 23:09:05) 3081bea1cdebfb9f8cea46f5c39f349a1a83436c]:
[[file:./fig-approximate-nuisance.pdf]]

* References

** References

\small \bibliography{/home/amnudn/Documents/latex/default-bib.bib}

* HEADER :noexport:
#+TITLE: Journal club -- Models as Approximations
#+Author: Anders Munch
#+Date: \today

#+LANGUAGE:  en
#+OPTIONS:   H:2 num:t toc:nil ':t ^:t
#+startup: beamer
#+LaTeX_CLASS: beamer
#+LATEX_CLASS_OPTIONS: [smaller]
#+LaTeX_HEADER: \usepackage{natbib, dsfont, pgfpages, tikz,amssymb, amsmath,xcolor}
#+LaTeX_HEADER: \bibliographystyle{abbrvnat}
#+LaTeX_HEADER: \input{/home/amnudn/Documents/latex/standard-commands.tex}
#+BIBLIOGRAPHY: /home/amnudn/Documents/latex/default-bib plain

# Beamer settins:
# #+LaTeX_HEADER: \usefonttheme[onlymath]{serif} 
#+LaTeX_HEADER: \setbeamertemplate{footline}[frame number]
#+LaTeX_HEADER: \beamertemplatenavigationsymbolsempty
#+LaTeX_HEADER: \usepackage{appendixnumberbeamer}
#+LaTeX_HEADER: \setbeamercolor{gray}{bg=white!90!black}
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+LATEX_HEADER: \setbeamertemplate{itemize items}{$\circ$}

# Check this:
# #+LaTeX_HEADER: \lstset{basicstyle=\ttfamily\small}

# For handout mode: (check order...)
# #+LATEX_CLASS_OPTIONS: [handout]
# #+LaTeX_HEADER: \pgfpagesuselayout{4 on 1}[border shrink=1mm]
# #+LaTeX_HEADER: \pgfpageslogicalpageoptions{1}{border code=\pgfusepath{stroke}}
# #+LaTeX_HEADER: \pgfpageslogicalpageoptions{2}{border code=\pgfusepath{stroke}}
# #+LaTeX_HEADER: \pgfpageslogicalpageoptions{3}{border code=\pgfusepath{stroke}}
# #+LaTeX_HEADER: \pgfpageslogicalpageoptions{4}{border code=\pgfusepath{stroke}}
